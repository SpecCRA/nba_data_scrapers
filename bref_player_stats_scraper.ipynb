{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create url templates for each kind of stats\n",
    "per_g_url_template = \"https://www.basketball-reference.com/leagues/NBA_{year}\\\n",
    "_per_game.html\"\n",
    "adv_url_template = \"https://www.basketball-reference.com/leagues/NBA_{year}\\\n",
    "_advanced.html\"\n",
    "tot_url_template = \"https://www.basketball-reference.com/leagues/NBA_{year}\\\n",
    "_totals.html\"\n",
    "per_36m_url_template = \"https://www.basketball-reference.com/leagues/NBA_{year}_\\\n",
    "per_minute.html\"\n",
    "per_100p_url_template = \"https://www.basketball-reference.com/leagues/NBA_{year}_\\\n",
    "per_poss.html\"\n",
    "\n",
    "# Put all the URL templates into a list\n",
    "url_template_list = [per_g_url_template, adv_url_template, tot_url_template, \n",
    "                     per_36m_url_template,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter start year in YYYY format: 1981\n",
      "Enter end year in YYYY format: 2017\n"
     ]
    }
   ],
   "source": [
    "# Ask user to input start and end years\n",
    "try:\n",
    "    user_start_year = int(input(\"Enter start year in YYYY format: \"))\n",
    "except:\n",
    "    print('Enter a valid 4 digit year.')\n",
    "    \n",
    "try:\n",
    "    user_end_year = int(input(\"Enter end year in YYYY format: \"))\n",
    "except:\n",
    "    print('Enter a valid 4 digit year.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year range accepted.\n",
      "Year is in numbers.\n",
      "1981\n",
      "Year format accepted.\n",
      "Year is in numbers.\n",
      "2017\n",
      "Year format accepted.\n"
     ]
    }
   ],
   "source": [
    "# Check if end year is after start year\n",
    "if user_end_year >= user_start_year:\n",
    "    print('Year range accepted.')\n",
    "else:\n",
    "    print('Year range is unacceptable.')\n",
    "\n",
    "# Check if formats are in YYYY format\n",
    "def check_year(user_input_year):\n",
    "    try:\n",
    "        int(user_input_year)\n",
    "        print('Year is in numbers.')\n",
    "    except:\n",
    "        print('Enter a valid 4 digit year.')\n",
    "        sys.exit()\n",
    "\n",
    "    if user_input_year > 999 and user_input_year < 10000:\n",
    "        print(user_input_year)\n",
    "        print('Year format accepted.')\n",
    "    else:\n",
    "        print('Enter a valid 4 digit year.')\n",
    "        sys.exit()\n",
    "    \n",
    "check_year(user_start_year)\n",
    "check_year(user_end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store data before appending to Dataframe\n",
    "column_headers = []\n",
    "player_data = []\n",
    "# Create empty DataFrame for following functions to fill\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty DataFrames for each set of pages\n",
    "df_adv = pd.DataFrame()\n",
    "df_per_g = pd.DataFrame()\n",
    "df_tot = pd.DataFrame()\n",
    "df_per_36m = pd.DataFrame()\n",
    "#df_per_100p = pd.DataFrame\n",
    "\n",
    "# Create df_list of DataFrames for looping\n",
    "df_list = [df_per_g, df_adv, df_tot, df_per_36m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column headers from each page\n",
    "# Assigns a new list of column headers each time this is called\n",
    "def get_column_headers(soup):\n",
    "    headers = []\n",
    "    for th in soup.find('tr').findAll('th'):\n",
    "        #print th.getText()\n",
    "        headers.append(th.getText())\n",
    "    #print headers # this line was for a bug check\n",
    "    # Assign global variable to headers gathered by function\n",
    "    return headers    \n",
    "    #column_headers = [th.getText() for th in soup.find('tr').findAll('th')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old function that's a mess\n",
    "def get_player_data(soup):\n",
    "    temp_player_data = []\n",
    "    for i in range(len(soup.findAll('tr')[1:])):\n",
    "        # temp list to store player data\n",
    "        player_row = []\n",
    "        \n",
    "        # Loop through 'td' tags to extract player data\n",
    "        for td in soup.findAll('tr')[1:][i].findAll('td'):\n",
    "            player_row.append(td.getText())\n",
    "        \n",
    "        # Append data to a list    \n",
    "        temp_player_data.append(player_row)\n",
    "        \n",
    "        # Replace global variable with gathered player data\n",
    "    print(temp_player_data)\n",
    "    player_data = temp_player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get player data from each page\n",
    "def get_player_data(soup):\n",
    "    # Temporary list within function to store data\n",
    "    temp_player_data = []\n",
    "    \n",
    "    data_rows = soup.findAll('tr')[1:] # skip first row\n",
    "    for i in range(len(data_rows)): # loop through each table row\n",
    "        player_row = [] # empty list for each player row\n",
    "        for td in data_rows[i].findAll('td'):\n",
    "            player_row.append(td.getText()) # append separate data points\n",
    "        temp_player_data.append(player_row) # append player row data\n",
    "    return temp_player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    r = requests.get(url) # get the url\n",
    "    soup = BeautifulSoup(r.text, 'html.parser') # Create BS object\n",
    "    \n",
    "    # call function to get column headers\n",
    "    column_headers = get_column_headers(soup)\n",
    "    \n",
    "    # call function to get player data\n",
    "    player_data = get_player_data(soup)\n",
    "    \n",
    "    # input data to DataFrame\n",
    "    # Skip first value of column headers, 'Rk'\n",
    "    df = pd.DataFrame(player_data, columns = column_headers[1:])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(input_year):\n",
    "    first_yr = input_year - 1\n",
    "    season = str(first_yr) + \"-\" + str(input_year)[2:]\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function drops empty rows an columns, drops duplicates, and changes\n",
    "# % character in columns\n",
    "def gen_cleaning(df):\n",
    "    # Convert values to numeric values first\n",
    "    df = df.apply(pd.to_numeric, errors = 'ignore')\n",
    "    \n",
    "    # Drop columns with no data\n",
    "    df.dropna(axis = 1, how = \"all\", inplace = True)\n",
    "    \n",
    "    # Drop rows with no data\n",
    "    df.dropna(axis = 0, how = \"all\", inplace = True)\n",
    "    \n",
    "    # Remove duplicates player inputs; ie. players who were traded\n",
    "    # I only kept the TOT per game season values\n",
    "    #df.drop_duplicates([\"Player\"], keep = \"first\", inplace = True)\n",
    "    \n",
    "    # Change % symbol to _perc\n",
    "    df.columns = df.columns.str.replace('%', '_perc')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function scrapes player data from multiple pages by start and end years\n",
    "def scrape_pages(url_template, start_year, end_year, output_df):\n",
    "    count = 0 \n",
    "    for year in range(start_year, (end_year+1)):\n",
    "        url = url_template.format(year = year) # grab URL per year\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html5lib') # Create soup item\n",
    "        \n",
    "        # Check to grab column headers\n",
    "        if count == 0: # only append column headers once\n",
    "            columns = get_column_headers(soup)\n",
    "            count += 1\n",
    "            \n",
    "        # grab player data for each year\n",
    "        player_data = get_player_data(soup)\n",
    "        \n",
    "        # Create temporary DataFrame first for each year\n",
    "        # Duplicates are removed before putting into bigger DataFrame\n",
    "        # These duplicates come from players playing on multiple teams in one season\n",
    "        # This script only keeps the TOT output as Tm\n",
    "        year_df = pd.DataFrame(player_data, columns = columns[1:])\n",
    "        year_df.drop_duplicates(['Player'], keep = 'first', inplace = True)\n",
    "        year_df.insert(0, 'Season', get_season(year)) # insert season year column\n",
    "        \n",
    "        # Append to big DataFrame for detailed cleaning\n",
    "        output_df = output_df.append(year_df, ignore_index = True)\n",
    "        \n",
    "    # Do common, general cleaning practices\n",
    "    output_df = gen_cleaning(output_df)\n",
    "        \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bunch of code is just for me to check things as I go\n",
    "\n",
    "#url = \"https://www.basketball-reference.com/leagues/NBA_2006_per_game.html\"\n",
    "#r = requests.get(url)\n",
    "#soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#column_headers = get_column_headers(soup)\n",
    "#player_data = get_player_data(soup)\n",
    "#df_test = pd.DataFrame(player_data, columns = column_headers[1:])\n",
    "#df_test = gen_cleaning(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.sort_values('PS/G', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[df_test['Player'] == 'Kobe Bryant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill each DataFrame with data scraped from their respective pages\n",
    "# Each print statement is a check for if any pages or functions give issues\n",
    "# Added timer to check how long this was taking\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_per_g = scrape_pages(per_g_url_template, user_start_year, user_end_year, df_per_g)\n",
    "print(\"Finished per g\")\n",
    "df_adv = scrape_pages(adv_url_template, user_start_year, user_end_year, df_adv)\n",
    "print(\"Finished adv\")\n",
    "df_tot = scrape_pages(tot_url_template, user_start_year, user_end_year, df_tot)\n",
    "print(\"Finished tots\")\n",
    "df_per_36m = scrape_pages(per_36m_url_template, user_start_year, user_end_year, df_per_36m)\n",
    "print(\"Finished per 36m\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time elapsed :\" +str((end - start) / 60) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all column names to see what needs to be cleaned\n",
    "\n",
    "print(\"totals\")\n",
    "print(list(df_tot))\n",
    "print(\"per game\")\n",
    "print(list(df_per_g))\n",
    "print(\"per 36 minutes\")\n",
    "print(list(df_per_36m))\n",
    "print(\"advanced\")\n",
    "print(list(df_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label columns properly by adding \"_tot\" to the end of some column values\n",
    "df_tot.columns.values[[7, 8 , 9, 11, 12, 14, 15, 18, 19]] = \\\n",
    "[df_tot.columns.values[[7, 8 , 9, 11, 12, 14, 15, 18, 19]][col] + \"_tot\" for col in range(9)]\n",
    "\n",
    "df_tot.columns.values[21:30] = [df_tot.columns.values[21:30][col] + \\\n",
    "\"_tot\" for col in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column titles again\n",
    "list(df_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop _perc columns from per_g and per_36m\n",
    "# Never mind, drop duplicates later on\n",
    "# Add _per_g and _per_36m to column values\n",
    "# Add _per_G to some values in df_per_g\n",
    "df_per_g.columns.values[[7, 8 , 9, 11, 12, 14, 15, 18, 19]] = \\\n",
    "[df_per_g.columns.values[[7, 8 , 9, 11, 12, 14, 15, 18, 19]][col] + \"_per_G\" for col in range(9)]\n",
    "\n",
    "df_per_g.columns.values[21:29] = [df_per_g.columns.values[21:30][col] + \\\n",
    "\"_per_G\" for col in range(8)]\n",
    "\n",
    "# Rename PS/G to PTS_per_G\n",
    "df_per_g.rename(columns={'PS/G': 'PTS_per_G'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_36m.columns.values[[7, 8, 9, 11, 12, 14, 15, 18, 19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if proper values were changed\n",
    "list(df_per_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_36m.columns.values[[8, 9, 11, 12, 14, 15, 17, 18]] = \\\n",
    "[df_per_36m.columns.values[[8, 9, 11, 12, 14, 15, 17, 18]][col] + \"_per_36m\" \\\n",
    "for col in range(8)]\n",
    "\n",
    "df_per_36m.columns.values[20:30] = [df_per_36m.columns.values[20:30][col] + \"_per_36m\" \\\n",
    "                                   for col in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns were changed properly\n",
    "list(df_per_36m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where '\\xa0' columns are for removal\n",
    "print(df_adv.columns[-5])\n",
    "print(df_adv.columns[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop '\\xa0' columns, last one first\n",
    "#df_adv.drop(df_adv.columns[-5], axis = 1, inplace = True)\n",
    "#df_adv.drop(df_adv.columns[19], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv.rename(columns = {'WS/48' : 'WS_per_48'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if columns were dropped properly\n",
    "list(df_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes later on season, player name, and team\n",
    "# Order of merges: tots, per_g, per_36m, adv\n",
    "# DFs: df_tot, df_per_g, df_per_36m, df_adv\n",
    "# Common things: Season, Player, Pos, Age, Tm, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_tot, df_per_g, how = \"left\", \n",
    "                 on = ['Season', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'FT_perc',\n",
    "                      '3P_perc', '2P_perc', 'FG_perc', 'eFG_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, df_per_36m, how = \"left\",\n",
    "                 on = ['Season', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'FT_perc',\n",
    "                      '3P_perc', '2P_perc', 'FG_perc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, df_adv, how = \"left\",\n",
    "                on = ['Season', 'Player', 'Pos', 'Age', 'Tm', 'G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns to make sure they're all right\n",
    "list(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to drop duplicate MP columns\n",
    "list(df_all.drop(['MP_x', 'MP_y'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['MP_x', 'MP_y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check of columns\n",
    "list(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check length of dataframe\n",
    "print(len(df_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null values with 0\n",
    "df_all.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address ambiguous positions and combination positions\n",
    "df = df_all.groupby(['Pos'])['Pos'].nunique()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows of 0s\n",
    "df_all = df_all[df_all['Pos'] != 0]\n",
    "\n",
    "# Check df_all length again\n",
    "print(len(df_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this position is a mistake\n",
    "# Check the value to see the player\n",
    "df_all[df_all['Pos'] == 'C-SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Bobby Jones' actual, commonly played position\n",
    "df_all[df_all['Player'] == 'Bobby Jones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of dual positions in DataFrame\n",
    "# Create empty DataFrame to audit dual position values\n",
    "# Create empty list to store indices\n",
    "column_names = list(df_all.columns.values)\n",
    "dual_pos_rows = []\n",
    "df_dual_pos = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all the dual positions by seeing which ones have a dash\n",
    "for pos in df_all['Pos']:\n",
    "    if \"-\" in pos:\n",
    "        if pos not in dual_pos_rows:\n",
    "            dual_pos_rows.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all dual position rows to a new DataFrame for auditing\n",
    "for pos in dual_pos_rows:\n",
    "    df_dual_pos = df_dual_pos.append(df_all[df_all['Pos'] == pos],\n",
    "                                    ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dual_pos\n",
    "\n",
    "# It looks like all these players moved teams before\n",
    "# Certain players have multiple positions or changed positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dual_pos.groupby(['Player']).size().reset_index(name = 'Count').sort_values(['Count'], ascending = False).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check what is going on with some players with multiple positions\n",
    "df_all[df_all['Player'] == 'Allen Iverson*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common position for this player\n",
    "df_all[df_all['Player'] == 'Allen Iverson*']\\\n",
    ".groupby(['Pos']).size().reset_index(name = 'Count')\\\n",
    ".sort_values(['Count'], ascending = False).iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['Player'] == 'Jim Jackson'].groupby(['Pos']).size().reset_index(name = 'Count').sort_values(['Count'], ascending = False).iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['Player'] == 'Allen Iverson*'].groupby(['Pos']).size().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in df_all[['Player', 'Pos']].head(n=2).iterrows():\n",
    "    #print(\"this is for i\")\n",
    "    #print(i)\n",
    "    print(\"this is for k\")\n",
    "    print(k.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a test DataFrame for me to use before trying it on the big DataFrame\n",
    "df_test = df_all.copy().head(n=10)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.iloc[0][1] # Grabs name\n",
    "df_test.iloc[0][2] # Grabs position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in df_test['Pos'].iteritems():\n",
    "    #print(k)\n",
    "    if k == 'C' or k == 'SG':\n",
    "        df_test['Pos'] = df_test['Pos'].replace(['C', 'SG'], 'Replaced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test['Pos'] = df_test['Pos'].replace(['C'], 'Replaced')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['Player', 'Pos']].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[['Player', 'Pos']].iloc[0] = 'Other Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mitigate multiple positions, we will assign the position the player most commonly plays\n",
    "\n",
    "# Check if a player has more than one common position\n",
    "\n",
    "# Create a dictionary of players and their most commonly played positions\n",
    "most_common_pos = {}\n",
    "\n",
    "# Use dictionary as key to replace 'Pos' values in the big DataFrame\n",
    "\n",
    "def clean_pos():\n",
    "    pass\n",
    "    # Loop through rows to check players' positions\n",
    "    \n",
    "    # Check if it is indeed their most common position\n",
    "    \n",
    "    # If not, replace it with the most common one\n",
    "    \n",
    "    # Return DataFrame with cleaned positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with top 25 single season scorers \n",
    "#df_top_25_scorers = df_all.sort_values('PTS_per_G', ascending = False).head(n=25)\n",
    "\n",
    "# Create a DataFrame with top 50 single season scorers \n",
    "#df_top_50_scorers = df_all.sort_values('PTS_per_G', ascending = False).head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV files and DONE!\n",
    "#df_all.to_csv(\"bref_1981_2017_player_data.csv\", encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_top_50_scorers.to_csv(\"bref_1981_2017_top_50_season_scorers.csv\", encoding = \"utf-8\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
